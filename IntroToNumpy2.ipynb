{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050cea51-08f4-4fb5-bcdd-23129f4caedd",
   "metadata": {},
   "source": [
    "### SElecting the right estimator/algorithms for out problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52b5f782-83af-4bf8-a1db-ef8eb5624f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#sklearn refers to machine learning models, algos as estimators\n",
    "#classification problem- predicting a category (heart disease or not)\n",
    "#sometimes we see (clf) classifier used as a classification estimator\n",
    "#Regression problem- predicting a number (selling price of a car)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62fcdd-e03a-4f69-8427-8b8c2ddbfe4e",
   "metadata": {},
   "source": [
    "## Picking a machine learning model for a regression problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26b5355a-b0b8-4188-8f5e-5bc986bb64d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can get various reallife or toy data sets to practice with from sklearn website itself\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dced4c9c-56eb-4f4e-8e5f-fd9ecfaaebe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"] , columns=housing[\"feature_names\"])\n",
    "housing_df\n",
    "#here we convert data into dataframe because we can see that in the above cell the dataset array is under \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a6830f1-9024-4f21-a6cf-fc14066eebdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2852a49b-26ba-435a-ba6e-263044faa530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we shall build an algo to use all other values to predict the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3442d2e-ced2-42f7-8b71-43d641a438f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440131"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import algorithm/estimator\n",
    "from sklearn.linear_model import Ridge\n",
    "#setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis =1)\n",
    "Y = housing_df[\"target\"]#median housing price in $100,000s\n",
    "\n",
    "#Split into train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X , Y, test_size =0.2)\n",
    "\n",
    "#Instantiate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "#Check the score of the model(on the test set)\n",
    "model.score(X_test, Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11a27c71-9563-4bf3-a37e-10387b4d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even if this returns an output without error in the lecture version it asks to return the \n",
    "#coefficient of determination of the prediction\n",
    "#coefficient of determination is a statistical meadurement theat examines the differences in one variable \n",
    "#can be explained by difference in other variable while predicting a given event\n",
    "#ways to improve our prediction\n",
    "#either give more data or use a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2afa6ea4-5718-4bf4-b561-fa627f7bb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble method basically uses combination of smaller models for better generalization than a single model\n",
    "#This will help in getting a better score\n",
    "# A Random forest is a combination of lots of different decision trees,default value 100 different decision trees\n",
    "# Import the RandomForestRegressor model class from the ensemble module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85b653-d96d-476b-aea7-25ffc58d3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an ensemble module just like we used a linear module previously\n",
    "#Random forest is a powerful algorithm and can be used both as a classifier and regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = housing_df.drop(\"target\", axis =1)\n",
    "Y = housing_df[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "#Create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Check the score of the model on the test set\n",
    "model.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50c5e5-f373-4c41-8527-5fa6828288c7",
   "metadata": {},
   "source": [
    "## Picking a machine learning model for a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672dbbc-913e-44e6-be18-c6a8b299b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartdis = pd.read_csv(\"C:/Users/Dell/Desktop/sample_project_1/heart-disease.csv\")\n",
    "heartdis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde4aac-d728-45be-a649-046454641b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consulting tge map lets try linear svc model first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857b3a5-7678-4a3c-89eb-703ede1c6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMport the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Make the data\n",
    "X = heartdis.drop(\"target\", axis =1)\n",
    "Y = heartdis[\"target\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size =0.2)\n",
    "\n",
    "#Instantiate LinearSVCd \n",
    "clf = LinearSVC(max_iter = 10000)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluate the LinearSVC\n",
    "clf.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed39ae-0126-4c4f-a3e5-694790b7afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartdis[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efff6c-5e56-4177-ac53-c7bfcffdf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target column in tge heart disease csvv produces either 1 or 0 as an answer to heart disease or not\n",
    "# that is why we set it as the target value or the value to be tested on and ultimately predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d52f5-08cf-469b-a4d3-8367a05e1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an ensemble module just like we used a linear module previously\n",
    "#Random forest is a powerful algorithm and can be used both as a classifier and regressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = heartdis.drop(\"target\", axis =1)\n",
    "Y = heartdis[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "#Create random forest model\n",
    "clf = RandomForestClassifier(n_estimators = 100)#this n_estimators argument can be given to specify\n",
    "# the number of decision trees that are to be taken and its default value is anyways 100\n",
    "#we have given this just to prevent warnings\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Check the score of the model on the test set\n",
    "clf.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7910e-4dd1-4847-ab2d-131ca548dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tips and tricks\n",
    "#1.If you have structured data use ensemble methods\n",
    "#2.If we have unstructured data use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564be3d2-fc0b-4838-9d82-36213465fa80",
   "metadata": {},
   "source": [
    "## Fit the model / algorithm and use it to make predictions on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943e34a-946f-47cf-a73f-1f7e778a1580",
   "metadata": {},
   "source": [
    "### Fitting the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bab3a-014f-48b3-8d20-0fd4efaeee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an ensemble module just like we used a linear module previously\n",
    "#Random forest is a powerful algorithm and can be used both as a classifier and regressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = heartdis.drop(\"target\", axis =1) \n",
    "Y = heartdis[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "#Create random forest model\n",
    "clf = RandomForestClassifier(n_estimators = 100)#this n_estimators argument can be given to specify\n",
    "# the number of decision trees that are to be taken and its default value is anyways 100\n",
    "#we have given this just to prevent warnings\n",
    "\n",
    "#Fit the model to the data(training machine learning model)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Check the score of the model on the test set(Evaluate the RandomForestClassifier )\n",
    "#or use the patterns the model has learned\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705d7da-5ec6-4b67-9c13-598880477012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = features/feature variables/data\n",
    "#Y = labels/targets/target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01c978-1b0b-4c18-8e2b-b897bb6dfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646f876-29d9-45bf-a928-dd5442f889b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a51ffe-5cf2-4ec3-88ed-0d2051fab845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What happens when we fit the model to the data ,\n",
    "#It actually goes through the labels and tries to understand what patterns in values lead to a certain value in target \n",
    "#1 or 0 ,similar to how a human may try to identify a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31333ebf-732b-444d-b572-58bc45b92b10",
   "metadata": {},
   "source": [
    "### Make prediction using a machine learning model\n",
    "2 ways to make a prediction\n",
    "1.predict()\n",
    "2.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1a4c2-d2c4-4abc-ae57-18995c259b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a trained model to make predictions\n",
    "clf.predict(np.array([1,7,8,3,4])) # this doesnt work...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9d90e-9c91-4e5f-bdf6-552a95fc10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above warning shows that data needs to be given in the exact shape or manner in which the \n",
    "# data on which the model was trained was in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9597d79-e670-45bd-a5c2-a4a7bcdec3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n",
    "# we can see that the prediction is in same format as the test labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace41e6-7386-49c6-849a-07bf0eb74c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb573e6-170a-4d5a-aee9-3eba322ec963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare predictions to truth labels to evaluate the model\n",
    "# which means we are basically checking the accuracy of the model\n",
    "Y_preds = clf.predict(X_test)\n",
    "np.mean(Y_preds == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457fde4-4153-4ef7-bf04-d3442ddacbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9dca4-7213-4b0d-bb30-9adb7a2fc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theres one more way of doing this\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46373be-dd81-4c01-b4a7-7b3b8c3edb72",
   "metadata": {},
   "source": [
    "#### Make predictions with predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094712f4-30f8-4af4-b8a9-7dc3a4045bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_proba() returns probabilities of a classification label\n",
    "clf.predict_proba(X_test[:5])\n",
    "                  #just the first 5 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9debae1-98f3-4f7c-9db1-ee67edb47023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the above case we can see that if we add numbers in each row the result is 1\n",
    "# so basically it returns the probability of the label being 0 and 1 in each case\n",
    "# this can be used in cases where we want to take only those samples where the machine is very confident\n",
    "#about any result that is instead of being 49:51 or 46:54 we get 89:11 or 22:78 or any desired probability threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283297a-bf3f-4e3a-a911-cfd1ec64d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use predict() on the same data\n",
    "clf.predict(X_test[:5])\n",
    "#here it returns the label(from 0 and 1) that has the higher probability of being the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511ac8c-9a0f-48bd-8199-d73d4d6a62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict() can also be used on regression models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac6487-6f56-48d8-9510-5fb1c5c7edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d42984-2956-43f8-87c4-924ccbbdad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the datas\n",
    "X = housing_df.drop(\"target\" , axis=1)\n",
    "Y = housing_df[\"target\"]\n",
    "\n",
    "#Split into training and test sets\n",
    "X_train, X_test,Y_train , Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "#Create model instance\n",
    "model= RandomForestRegressor()\n",
    "#Fit model to the data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Make predictions\n",
    "Y_preds = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8e151-8757-4ee3-9cb9-6336073f3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds[:10]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b023ae-2bf4-4fc2-8762-9baa22e7d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f9ef9-8940-4d05-875b-9e5309080943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the predictions to thetruth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c3e80-38a8-421d-90cf-c1b7763fe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on average each value of our prediction is 0.32 different than the actual value\n",
    "housing_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea975c0-2876-42b6-bc99-c80e83ce6bea",
   "metadata": {},
   "source": [
    "## Evaluating a machine learning model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2718d-1c9d-410c-a6b5-15147d93500b",
   "metadata": {},
   "source": [
    "#### Three ways to evaluate Scikit-Learn models/estimators:\n",
    "#### 1.Estimator's built-in 'score()' method\n",
    "#### 2. The 'scoring' parameter\n",
    "#### 3. Problem-specific metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e723fe0-36ac-4092-a0f2-44378b5e213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = heartdis.drop(\"target\", axis =1) \n",
    "Y = heartdis[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "#Create random forest model\n",
    "clf = RandomForestClassifier(n_estimators = 100)#this n_estimators argument can be given to specify\n",
    "\n",
    "#Fit the model to the data(training machine learning model)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283abba5-da24-48d5-a31e-bee29560315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d446101-9e05-4409-9ffb-50e5ba4dd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The highest value for the .score () method is 1.0, the lowest is 0.0(it returns the mean accuracy)\n",
    "# here it gives 1 because the data is the train set not test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410a411-f1d3-4f72-bd47-f18916f641e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The coefficient of determination is the proportion of dependent variable (target here) is dependent on\n",
    "# the independent variable\n",
    "#By increasing the no of estimators we increase the number of decision trees we can improve our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e6aaa-0fe6-4f1f-b9cd-e7ca4a8f92a5",
   "metadata": {},
   "source": [
    "### Lets checkout the scoring parameter and use it to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016a21c-f506-4deb-9915-8043c391a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Create the data\n",
    "X = heartdis.drop(\"target\", axis =1) \n",
    "Y = heartdis[\"target\"]\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "\n",
    "#Create random forest model\n",
    "clf = RandomForestClassifier(n_estimators = 100)#this n_estimators argument can be given to specify\n",
    "\n",
    "#Fit the model to the data(training machine learning model)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224aa69b-b137-492e-b6e4-635db5ecc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 0.2 we use in test size is 20% of the data is test data and rest data is used to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca3f39-d1bd-40a6-ad22-842d47e8b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0f9aa-aa0e-4da4-ad65-4d4af43f66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X,Y,cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a58c00-ebae-430b-ad11-324d7c467c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossval score returns an array instead of value like score\n",
    "#here we have taken cv = 5 which means 5 fold cross validation i.e it takes the same 20% of data for testing\n",
    "# but it takes that 20% section from different parts of the total data , not the same 20% every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640ce46-fe26-408d-b360-da2112987c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#Single training and test split score\n",
    "clf_single_score = clf.score(X_test,Y_test)\n",
    "\n",
    "#Take the mean of 5-fold cross-validation score or the mean of 5 values\n",
    "clf_cross_validation_score = np.mean(cross_val_score(clf,X,Y,cv=5))\n",
    "\n",
    "#Compare the two\n",
    "clf_single_score, clf_cross_validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c0fdc-4c14-4890-b9f9-03bafb01dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default scoring parameterof classifier = mean accuracy\n",
    "clf.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ef19d-ff30-44cc-b725-fa6346c6139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Parameter set to None by default\n",
    "cross_val_score(clf, X,Y,cv=5,scoring= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee487fb-a2b6-43b0-ab44-7bb4ffd46b4d",
   "metadata": {},
   "source": [
    "### Classification model evaluation metrics\n",
    "\n",
    "1.Accuracy\n",
    "2.Area under ROC curve\n",
    "3.Confusion matrix\n",
    "4.Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6acee-c1c9-43d8-b3ed-ffc2cfd70f86",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311659c4-a0b9-4a41-9d1a-1b6e381abb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heartdis.drop(\"target\" , axis = 1)\n",
    "y = heartdis[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators =100)\n",
    "cross_val_score = cross_val_score(clf, x, y , cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f006a-bde6-432b-9b90-862f2970a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)\n",
    "#mean accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00926dba-3021-4372-a28f-0978f36d3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Accuracy: {np.mean(cross_val_score) *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b079e47-0d40-4400-b526-cd23fe05ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This basically gives how likely our model is to predict the right target based on the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81172a33-1eb3-4a10-b189-e447075bd8e2",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb0ac6-508d-4726-9899-278189d6e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area Under Receiver Operating Characteristic curve (AUC/ROC)\n",
    "\n",
    "#ROC curves are a comparison of a model's true positive rate (TPR) versus a models false positive rate(FPR)\n",
    "#True positive = model predicts 1 when truth is 1\n",
    "# False positive = model predicts 1 when truth is 0.\n",
    "#True negative = model predicts 0 when truth is 0.\n",
    "#False negative= model predicts 0 when truth is 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402346b-4683-400d-a62b-9f761a8ed8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X_test Y_test etc\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c66bb2-9b03-4c4a-90fe-0f43b9bf717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#roc_curve is imported\n",
    "\n",
    "#Fit the classifier to the train and test\n",
    "clf.fit(X_train, Y_train)\n",
    "# we have already separated x and y in the previous blocks\n",
    "\n",
    "#Make predictions with probabilities\n",
    "Y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "Y_probs[:10]\n",
    "#recall that the left value is probability of getting target 0 and right is the probability of getting 1\n",
    "#show the first 10 prediction using proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5f99e-ff37-4369-a1ce-9c0dd38fbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_probs)\n",
    "#there are 61 such values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8b94-60e3-42ca-bdee-a8412018d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But for ROC we need only the positive value prediction , i.e for the 1s\n",
    "Y_probs_positive = Y_probs[:, 1]\n",
    "#Chooses only the elements of column 1\n",
    "Y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168f0ac-8dc7-4770-acfc-f17cfc8efad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr , tpr , thresholds = roc_curve(Y_test, Y_probs_positive)\n",
    "#roc_curve takes parameters test data and positive value prediction as input\n",
    "\n",
    "#Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491dd2d1-91a4-41c2-95fa-99f9453c768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will make more sense when the roc curve is plotted instead of just a bunch of arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8d94-e0a1-4b48-950b-26fd181bd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    #This will plot a curve given the fpr and tpr of a model\n",
    "    plt.plot(fpr, tpr , color=\"orange\" , label = \"ROC\")\n",
    "    #Plot line with no predictive power (baseline)\n",
    "    plt.plot([0,1], [0,1], color = \"darkblue\" ,linestyle=\"--\" , label=\"Guessing\")\n",
    "\n",
    "    #Customise the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate(tpr) \")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03410d3-b03c-4857-a21f-53537e390111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(Y_test, Y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c24379-0523-48de-a1b2-cbc13ba6d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ideal curve should get a score 1, it would cover the entire graph under it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a85ca7-b164-4ee8-85f4-c44409e33a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_test)\n",
    "#here we take the same data for training and testing to get perfect predictions\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba87dee-8b4b-40ca-8d7f-acda295ce545",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(Y_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa4c6a-2eb9-4179-a3d9-01a635e1b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curves and AUC metrics are evaluation metrics for binary classification models\n",
    "#The AUC metric tells us how good our model is at choosing between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc4880-8470-483f-85e0-44c54a9de271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aff2417-d9f9-4847-b1e5-bf5b534f5ba1",
   "metadata": {},
   "source": [
    "**Confusion Matrix** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb972fc8-85c7-49ab-a2aa-8e460f30b84b",
   "metadata": {},
   "source": [
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict.\n",
    "In essence , giving us an idea where our model is getting confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8986d8-f76a-4b0c-852a-1fcb6442ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5e466-e2ed-4b15-997c-db883738f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets represent this in the form of crosstab to understand it better\n",
    "pd.crosstab(Y_test,\n",
    "             Y_preds,\n",
    "             rownames=[\"Actual Label\"],\n",
    "             colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dc89d-6479-4aa5-b710-52d1a873856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see that when the actual label is 0, the model predicted 0 in 22 cases and 1 in 7 cases\n",
    "# when the actual label is 1 , the machine predicts 0 in 8 cases and 1 in 24 cases\n",
    "# if we add all the cases we can find that the total is 61 no. of predictions which is same as the total predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf244d-cc8e-45a6-8eb0-f01e3f8151e4",
   "metadata": {},
   "source": [
    "here we can aslo see that the above are nothing but fpr and and tpr  values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f84598-f305-4745-a98c-b9c1d6fab216",
   "metadata": {},
   "source": [
    "\\ this diagonal is true positive and true negative\n",
    "/ this diagonal is false positive and false negative respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92535c5a-b81b-4adb-a684-ad8f16c60268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to install a conda package into the current environment from a Jupyter Notebook \n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadf038-2dce-4bda-b6b6-e0e127cc8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# set the font scale\n",
    "sns.set(font_scale =1.5)\n",
    "\n",
    "#Create a confusion matrix\n",
    "conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "\n",
    "#Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8b25a-9e5d-4e49-b172-f37448755356",
   "metadata": {},
   "source": [
    "### Creating a confusion matrix using Scikit-learn\n",
    "To use the new  methods of creating a confusion matrix with Scikit learn you will need sklearn version 1.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1212c-717a-4f9e-95aa-e00f4f6c23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b3f6a-8865-475e-878a-113621564ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d561a-5380-4c78-a9f4-d60693b162ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true= Y_test, \n",
    "                                        y_pred= Y_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c5578-1b02-4a85-bb1d-d797508f6739",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99132eee-89ad-4f34-84ed-bba9657e9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, Y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192613f-f4b3-47a7-b193-3ca9e73da051",
   "metadata": {},
   "source": [
    "#Precision- Indicates the proportion of positive identifications(model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0\n",
    "#Recall - Indicates the proportion of actual positives which were correctly classified . A model which produces no false negatives has a recall of 1.0\n",
    "#F1 score- A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "#Support- The number of samples each metric was calculated on.\n",
    "#Accuracy- The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\n",
    "#Macro avg- The average precision,recall and F1 score between classes. Macro avg doesnt class imbalances into effort so if you do have class imbalances pay attention to this metric.\n",
    "#Here we have very less class imbalances as there are 29 and 32 classes respectively (almost 50:50)\n",
    "#Weighted avg- Weighted average precision , recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1a343-a668-420b-b585-c3f90de8e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create our own data set to understand why classification report can be useful\n",
    "\n",
    "disease_true = np.zeros(100000)\n",
    "# it contains 1000000 zeroes\n",
    "\n",
    "disease_true[0] =1 # and only one positive case \n",
    "\n",
    "disease_preds = np.zeros(100000) # this model predicts every case as zero\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d4761-f1d8-4f8c-b129-c6096fac9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can see that the model has accuracy 99% but when we notice the precision we can see that it gets 0 precision as it did not even predict 1 in most cases\n",
    "# this tells us that despite having a high accuracy thr model is not usable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa07163-67e1-4f8a-8680-f325b20e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Till now we have seen few techniques to evaluate a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d89ce0-6a05-4415-8906-b9d5c0c4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets checkout evaluation techniques for Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d414848-df6f-4ccf-9d3c-e980024a8f3f",
   "metadata": {},
   "source": [
    "## REGRESSION Model Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249ba38-8e8a-4ed4-984e-af496ec2bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = housing_df.drop(\"target\" , axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size =0.2)\n",
    "model = RandomForestRegressor(n_estimators= 100)\n",
    "model.fit(x_train, y_train)\n",
    "# fit the model to train set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882c982-c562-4919-9867-c216d27f76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5a03f-45d5-4616-832a-ab9553d21cbb",
   "metadata": {},
   "source": [
    "## R^2-R squared evaluation metrics (or Coefficient of Determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfabe9-2129-4ca2-a4dd-74981897f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically tells us how much the dependent variable (target here) can be predicted by the independent variables\n",
    "# Compares your models predictions to the mean of the targets. Values can range from negative infinity to 1\n",
    "# so if all our model does is to predict the mena of the targets its R^2 value would be 0.\n",
    "# and if everything is predicted right the value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698f078-48a5-4961-bfa8-f51f31ab7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7026de-29fd-4001-b856-919970f2d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac71169-c553-40af-b925-40572c2b938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Lets Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "# create a full array with length od y_test and values y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96936592-986b-436c-8786-3414dce5de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b255d-e8e5-453d-beff-99c916a7a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true = y_test,\n",
    "        y_pred= y_test_mean)\n",
    "# by clicking shift + tab inside the function bracket we can easily determine the parameters or argument \n",
    "# that the function needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b219f4-0f8c-4093-9400-9115bf4ae252",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true= y_test,\n",
    "         y_pred= y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4d33f-bca9-478e-a96f-a97c78d59928",
   "metadata": {},
   "source": [
    "## Another metric(MAE -mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03e7b8-4778-438b-8ed2-6564eaa85e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE is the absolute differences between  predictions and actual values\n",
    "# it gives us an idea of how wrong our model predictions are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96260a4d-f2f5-4060-96a6-070500a5cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_preds = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f3991-edb1-4c23-9c20-6e9cec87b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e93538-8c43-4ef0-903c-b39b5630bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so basically 0.3265 .... tells us that each actual value is actually +- 0.32 of our predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c5c40-29b8-43bb-afa9-d7d020a208b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"actual values\":y_test,\n",
    "                          \"predicted values\":y_preds})\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684cc02-f88b-4952-ac0a-a86cd66e67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c335-7406-43d6-98e8-a92ca5e8efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this value comes different due to the negative values\n",
    "np.abs(df[\"differences\"]).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aed198-7902-4849-876f-a36e525d6c23",
   "metadata": {},
   "source": [
    "**MEAN squared error(MSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525298f-785c-4805-b450-466d360e707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE is the mean of the square of errors between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f78c17-1ccf-47b2-b8bf-a468292ac26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c999bf0-cf05-4a9d-96e6-a75a2d29ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the mse by hand\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f06689-400d-4568-8f0e-07aaa6b35f6f",
   "metadata": {},
   "source": [
    "**Which regression metric should you use?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbe14c-ce93-4b95-94cb-c05d034da953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R^2 is similar to accuracy. It gives you a quick indication of how well your model might be doing.\n",
    "#Generally the closer your R^2 value is to 1.0  the better the model. But it doesnt really tell exactly how \n",
    "#wrong your model is in terms of how far off each prediction is .\n",
    "# MAE gives a better indication of how far off each of your model's  predictions are on average.\n",
    "#As for MAE or MSE , because of the way MSE is calculated , squaring the differences between predicted values and actual \n",
    "#values , it amplifies larger differences. \n",
    "#For example while calculating the value of MAE being 10000 off is twice as bad as being 5000 off\n",
    "#For mse, being 10000 off is more than twice as bad as being 5000 off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a85f62-2b14-4778-ab70-796542320f1d",
   "metadata": {},
   "source": [
    "**Which classification metric should you use?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bf622-25d8-4770-ac6f-09bd47c8b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy : accuracy is a good measure to start with if all classes are balanced (e.g. same amount \n",
    "#samples which are labelled with 0 or 1)\n",
    "#Precision and recall become more important when classes are imbalanced\n",
    "#If false-positive predictions are worse than false-negatives, aim for higher precision\n",
    "#If false-negative predictions are worse than false-positives aim for higher recall.\n",
    "#F1 score is a combination of precision and recall.\n",
    "#A confusion matrix is always a good way to visualise how a classification model is going"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c867b5d-dd95-4343-a3e9-a41939324da6",
   "metadata": {},
   "source": [
    "# Finally using the scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03c685-27fa-4ece-94c9-587146cd1a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb4e6d-0586-4b17-bc0f-c46f1e19e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heartdis.drop(\"target\" , axis= 1)\n",
    "y = heartdis[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d57720-ac26-486c-a738-787f2353dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "#if we recall the process of cross validation we divided the data set into multiple train and test sets\n",
    "#and getting average of scores for different splits\n",
    "#Cross validation  accuracy cv_acc\n",
    "cv_acc = cross_val_score(clf,x,y,cv=5, scoring = None)#splits into 5 different train and test sets\n",
    "#Scoring = none means default scoring evaluation for the model is used\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29661073-dc04-4523-8790-e90526e43f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is :{np.mean(cv_acc)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afaebd-920e-4a45-90c5-644fb2220f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf,x,y,cv=5, scoring = \"accuracy\")\n",
    "cv_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd22db3-3da2-4bf8-b359-4951a2ee6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "cv_pre = cross_val_score(clf,x,y,cv=5, scoring = \"precision\")\n",
    "cv_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45dea5-dc6f-4d9f-9233-57cf5b90d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_validated precision\n",
    "print(f\"The cross-validated precision is :{np.mean(cv_pre)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb375f1-6f4a-4b91-9834-34c41a9371b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall\n",
    "cv_rec = cross_val_score(clf,x,y,cv=5, scoring = \"recall\")\n",
    "cv_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add943d0-2c4b-4363-b94c-3b35016ae447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cross-validated recall is :{np.mean(cv_rec)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064239c-b710-4310-bbdf-54b8869d61a8",
   "metadata": {},
   "source": [
    "## Scoring parameter for regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82700c34-83a2-4278-97ce-8ce3daf4b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need a regression model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heartdis.drop(\"target\" , axis =1)\n",
    "y = heartdis[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d79bbb-15fb-46e7-991e-ff1be0c7615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "#Cross-validation accuracy\n",
    "cv_acc2 = cross_val_score(model, x, y, cv =3 ,scoring = None)\n",
    "np.mean(cv_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04367386-6e91-4dfc-ba6b-c524db0a9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa5919-5376-44ca-aeb1-6ca508d190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean absolute error\n",
    "cv_mae = cross_val_score(model, x, y , cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353d0b4-32cd-4733-8691-5e6611a6bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squareed error\n",
    "cv_mse = cross_val_score(model, x, y ,cv=3,scoring =\"neg_mean_squared_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3fc49a-53cc-4d89-98cc-3372d903f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304eafbf-306a-43e5-ab05-4e8a71564084",
   "metadata": {},
   "source": [
    "## Using different Evaluation metrics as Scikit-learn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e315fb1-5b43-47e9-a46d-25e90751c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The third way to evaluate sci-kit learn machine learning models/estimators is to use the skelearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81704b-7b1f-4cde-8218-80908edc4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heartdis.drop(\"target\" ,axis =1)\n",
    "y = heartdis[\"target\"]\n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(x, y, test_size =0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "clf.fit(x_train , y_train)\n",
    "\n",
    "y_preds=clf.predict(x_test)\n",
    "\n",
    "#Evaluating the functiion using evaluation functions\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test,y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test,y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29195e2-5cc5-464d-adb6-0d6fb9e8e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = heartdis.drop(\"target\" , axis =1)\n",
    "y = heartdis[\"target\"]\n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(x, y, test_size =0.2)\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "#Fit model\n",
    "model.fit(x_train , y_train)\n",
    "\n",
    "y_preds=model.predict(x_test)\n",
    "\n",
    "#Evaluate the model using evaluation functions\n",
    "print(\"Regression metrics on the test set\")\n",
    "print(f\"R2 score: {r2_score(y_test,y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test,y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test,y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac10abd-7ffc-41ce-9896-c5ee4264671e",
   "metadata": {},
   "source": [
    "##  Improving a machine learning model\n",
    "##### First predictions=baseline predictions\n",
    "##### First model= baseline model\n",
    "\n",
    "From a data prespective:\n",
    "##### ->Could we collect more data?(the more data the better)\n",
    "##### ->Could we improve our data\n",
    "\n",
    "From a model prespective\n",
    "##### ->Is there a better model we could use?\n",
    "##### ->Could we improve the current model?\n",
    "\n",
    "##### Parameters=model finds these patterns in  data\n",
    "##### Hyperparameters = settings on a model you can adjust(potentially) to improve its ability to find patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ad6e5-21e1-4dcf-8ffd-66ca94b7d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to set hyperparameters\n",
    "#Here we want the machine to find out the pattern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#get the list of parameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c0a3c-9eda-41e1-abf3-b090908a6d8f",
   "metadata": {},
   "source": [
    "## Three ways to adjust hyperparameters\n",
    "##### 1.by hand\n",
    "##### 2.randomly with RandomSearchCV\n",
    "##### 3.exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ad344-73c4-430e-94fe-313349a76c84",
   "metadata": {},
   "source": [
    "## By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fca1da-1604-44c0-8da4-a7f7b13d7807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "img = Image.open('C:/Users/Dell/Desktop/sample_project_1/Images/IMG20240613123223.jpg')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1968b7b-8b89-432d-8a73-6816d1bdb804",
   "metadata": {},
   "source": [
    "## Generalisation- the ability of a machine learning model to perform well on data it hasn't seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626dc0d-07f8-40f3-8b28-2693d62dd6ec",
   "metadata": {},
   "source": [
    "#### Lets divide the data into 3 sets, training ,test and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5be31-17f3-4c8a-b9f7-b5678714295e",
   "metadata": {},
   "source": [
    "### We're going to try and adjust\n",
    "### max_depth\n",
    "### max_features\n",
    "### min_samples_leaf\n",
    "### min_samples_split\n",
    "### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74721b-7a1e-4eff-9e60-f17be60fd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true,y_preds):\n",
    "    #Perform evaluation comparision on y_true labels vs y_preds labels on a classification\n",
    "\n",
    "    accuracy=accuracy(y_true,y_preds)\n",
    "    precision=precision_score()\n",
    "    recall=recall_score()\n",
    "    f1=f1_score()\n",
    "\n",
    "    metric_dict={\"accuracy\":round(accuracy,2),\n",
    "    \"precision\":round(precision,2),\n",
    "    \"recall\":round(recall,2),\n",
    "    \"f1\":round(f1,2)}\n",
    "\n",
    "    print(f\"Acc:{accuracy*100:2f}%\")\n",
    "    print(f\"Precision:{precision:.2f}\")\n",
    "    print(f\"Recall:{recall:.2f}\")\n",
    "    print(f\"F1 score:{f1:.2f}\")\n",
    "\n",
    "\n",
    "    return metric_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308b5ff-75e3-49dc-a9ae-96a4cd82694b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "#Shuffle the data\n",
    "heartdisshuffled=heartdis.sample(frac=1)\n",
    "\n",
    "#Split into x and y\n",
    "x = heartdisshuffled.drop(\"target\",axis=1)\n",
    "y= heartdisshuffled[\"target\"]\n",
    "\n",
    "#Split data on train , validation and test sets\n",
    "train_split = round(0.7 * len(heartdisshuffled))#70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heartdisshuffled)) #15 % of data\n",
    "x_train,y_train= x[:train_split],y[:train_split]\n",
    "x_valid,y_valid = x[train_split:valid_split], y[train_split:valid_split] #upto train split\n",
    "x_test,y_test= x[valid_split:], y[valid_split:] # train split to valid split\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#Make baseline predictions\n",
    "y_preds = clf.predict(x_valid)\n",
    "\n",
    "#Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf684e0f-54f6-4c81-bf9c-d5f4bab258f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51634707-5671-4562-a0d4-575c80ecbbc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'accuracy' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_preds_2 \u001b[38;5;241m=\u001b[39m clf_2\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Evaluate the 2nd classifier\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m clf_2_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preds_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m, in \u001b[0;36mevaluate_preds\u001b[1;34m(y_true, y_preds)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_preds\u001b[39m(y_true,y_preds):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#Perform evaluation comparision on y_true labels vs y_preds labels on a classification\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     accuracy\u001b[38;5;241m=\u001b[39m\u001b[43maccuracy\u001b[49m(y_true,y_preds)\n\u001b[0;32m      5\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision_score()\n\u001b[0;32m      6\u001b[0m     recall\u001b[38;5;241m=\u001b[39mrecall_score()\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'accuracy' referenced before assignment"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "#Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators =100)\n",
    "clf_2.fit(x_train,y_train) \n",
    "\n",
    "#make predictions with different hyperparameters \n",
    "y_preds_2 = clf_2.predict(x_valid)\n",
    "\n",
    "#Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe84e40-ba1c-4b11-94e8-9255b28b5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562854ae-1c43-4584-9483-089b2a336e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f62be3-7c67-4c42-9cad-4d6dbfece01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f1fdd-63c6-40c8-ad48-070bea0e8658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44cfa2-2368-4459-a578-4436fac15320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f238d-645e-4bb2-acfd-31c10f487a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b2190-ea53-49d7-9881-b734de17534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9008352-6240-4f3d-a57e-50c03f827774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088934-4985-47e0-a01c-50ddd0f8aaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05945382-ef9a-47f6-9db8-ccea362d39e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7c293-11f6-498f-81a9-ebe312ceb561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7a3d7-cd93-4d70-8e6d-5b6f7f686208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83551ac-a2d7-458a-8101-9885c3b32064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a01a63-fccd-4b66-bbcc-704580f78373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93100a-9605-4e14-b9d4-637cfa80bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbad5e-90a8-4cc5-8110-53fcef62cde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a51220-276a-4fc2-9f1f-514f284865e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154f8f9-58ae-4941-a1d3-766611c9961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72895b0-3c08-409e-9a46-115a9b1a55a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da415a22-2709-4ca2-aa57-2eabf98eca7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41f721-ddb7-4996-8f46-1ab43576190a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6218a-6822-4ea1-83b7-9f41a9cdb1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a34e31-5aa5-4655-a432-eb475d9e8564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aca81e-fa2c-44aa-8082-5f3b5e5441e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2655932-684a-48b2-b561-13b9808e426d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803ce36-cd89-4b62-ba3d-74e5befa1541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cba06b-26ce-4bd2-8fc1-aa3d90050300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb03a0c-609d-463c-889b-59385044ce8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984e238-efd6-4d07-aab9-98a5c631dc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff9c56-0b27-489d-bfaf-45000ea13eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c7516-a897-41fa-a883-346940027b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75db97-6861-46cf-8baa-c454abf8103c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a84fb-16d8-4d18-ba1f-b897d10425d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d04933-7658-46e1-a7ab-a5df1f723109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f30aaa-0caf-4079-a53f-7beb55056d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccf8f4-802f-46bd-b2cc-5fd4a2a2be32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ea19d-b07c-4bac-8bd8-191939931337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f03b74-5543-4667-95fc-555b613a1b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b54472-5fec-415a-9ef2-ab2701e2cd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5f52b-438d-4902-a7ad-8e57be634088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c8396-52d1-4ad9-9f7c-259bc80bbfab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a44925-3621-4fca-8540-8d9f1086feef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0e326-796c-4a34-a1f6-eba19e9177c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23dac1-9e0f-492e-abf2-f7c85839a71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07378abb-66a3-478f-8749-a26ba5b29c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80831d59-88cc-4461-9e85-49993c5f30eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea9573-08a3-460e-994f-032fc6f0ac6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f490e2-9ac4-406f-99e1-37682ab3787f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbef118-7fcf-4dec-ac75-396fffcb1971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926622b0-bd5e-410e-8f5b-58ba244ddf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272edeb9-4218-4d9b-9cfd-1da0a0fffacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43833b-aaf6-4a32-8c61-f816d28aa16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82029c9-8f5a-449d-9e20-024a434dd4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8432740-7fde-4658-a0d1-f987ad0cab10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3ede5-0503-424a-8536-202798e9d8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e8bd4-b0aa-4c89-a578-a3dda1114d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e27d67-e422-42aa-9622-55ef86cc43fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0162b7-9de2-4b8f-8482-c2684b11d0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c17078-6c38-416d-afcc-0ad17171628b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b5b0a-c58f-4ecb-b0ec-74ab171b8e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b3192-be41-4878-abe7-8de4c1140bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ca641-c0f4-4aeb-89a9-bad5371ad700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef89b4a-b2ca-4c0d-bcdf-64104771dc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37546892-8eab-44d6-bf79-3650f0a4674e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e2744-d67d-4616-a879-054588648312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0a7a7-b0d9-4581-b834-367f514f2462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcf687-8b49-465f-8130-321fd8d1e543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c2ec4-f56c-46b6-8b73-42836eb0f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796461a-a68f-45e2-bd99-441724d3e510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f499f2-303a-4e92-b991-6e3d5cb20ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469afc4-2a0f-4e6b-8589-b0f2ba57bc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f050d-fd3c-4c09-b0ab-b0d57452891f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80df9e-0886-4a19-aa5f-a6c261272688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aeb6b8-2eea-4ff0-95a6-2b3fd519c23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e194b-b419-47a6-8361-323a42ce08dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2238820-82c8-4759-a9de-19dedcd0c06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48780e-d008-4cf9-b5b3-85561c66a862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ed331-eb10-4d48-8e77-af0a932de66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ead964-fe00-4360-a9d5-a55f73aa3545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ebc17-66cc-4b4a-af31-4b1a75c7d130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfba9cc-004a-46fe-8ff3-cd241d034e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293989e-39d4-4720-93d2-81a800b76ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff402a9e-a61f-402b-afff-64bf2f2116fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab96de-aee2-4dd0-b44a-8fe7917de010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7848de4-bae6-4de5-9f3f-157146ef7e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abc667-8d7f-403f-91ca-0b5528a5898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47bffc-12c4-4fd8-92aa-527a87e8e229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a834f-1dd7-4734-b81d-c3cbdfadb425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857230d0-7c69-4a85-8d5c-e2611517ae68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea6dca-36f1-49e1-aa34-83218d81d4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819e3a0-ed62-4407-b444-485163813a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3973dd4-6721-4d09-8846-10504c5cf439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8607d52-f93b-43c0-9e3b-f66cbfcad576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
